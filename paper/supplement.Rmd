---
title: "Supplement"
output: pdf_document
date: "2023-03-28"

header-includes:
 - \usepackage{tikz}
 - \usetikzlibrary{positioning,arrows.meta, quotes, shapes}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # By default, hide code; set to TRUE to see code
#knitr::opts_chunk$set(fig.pos = 'th') # Places figures at top or here
knitr::opts_chunk$set(out.width = '100%', dpi=300,
                      fig.width=8, fig.width=8) # Figure resolution and size
knitr::opts_chunk$set(fig.env="figure") # Latex figure environment

options(knitr.table.format="latex") # For kable tables to work without setting format option

knitr::opts_chunk$set(echo=F, warning=F, message=F)#dev = "png", dev.args = list(type = "cairo-png")
 library("papaja")
library("bookdown")
library("rticles")
 library(here)
 library(tidyverse)
 library(brms)
library(tidybayes)
library(kableExtra)
library(viridis)
library(cowplot)
library(ggthemes)
#r_refs("r-references.bib", append=F)
theme_set(theme_bw())
options(knitr.table.format = "pdf")

model_location="code/models"
d <- read_csv(here("data", "processed_data.csv")) |> filter(status!="unusable") |> filter(include!="no")

```

# Additional model results

Per our pre-registration, we ran a set of 6 models crossing 3 outcome measures (subjective replication score, whether the replication result was within the prediction interval of the original, and p-original on the hypothesis that both came from the same distribution) with 2 sets of predictors (with or without statistical predictors). These 6 models required 3 tiers of data: the subjective replication score without statistical predictors applies to all the data; the p_original and prediction interval models apply to the subset of data with numeric outcomes that can be compared; and the statistical predictor models need the smaller subset of data with p-values and original standardized effect size in particular. 

Due to low sample sizes and large numbers of predictors, even with regularizing priors, the coefficient estimates generally have a lot of uncertainty. 

## Sensitivity Analysis

As a check on whether our results were sensitive to the inclusion of pairs that were marginal in some way, we repeated the 6 models including only studies that were not marginal. 

```{=latex}
\definecolor{bad}{HTML}{FFCCCB}
		\definecolor{meh}{HTML}{efefef}
			\definecolor{good}{HTML}{abcdff}
	\tikzset{
		mynode/.style={
			draw, rectangle, align=center, text width=4.5cm, scale=1, font=\small, inner sep=.5ex},
		arrow/.style={
		 very thick,->,>=stealth}
	}
	
\begin{figure}
	\begin{tikzpicture}[auto,
		node distance = 6mm and 30mm,
		every edge quotes/.append style = {font=\footnotesize, text=black, text centered}
		]
		\node (n1) [mynode, fill=good] {\textbf{112} pairs with statistical predictors};
		\node (n2) [mynode, below=of n1, fill=good]       {\textbf{24} additional pairs for p-original and prediction interval};
		\node (n3) [mynode,below=of n2, fill=good]    {\textbf{40} additional pairs for subjective replication};
		
		\node (n4) [mynode, fill=meh, right=of n1] {\textbf{82} pairs with statistical predictors};
		\node (n5) [mynode, below=of n4, fill=meh]       {\textbf{18} additional pairs for p-original and prediction interval};
		\node (n6) [mynode,below=of n5, fill=meh]    {\textbf{67} additional pairs for subjective replication only};
		\node (n7) [mynode,below=of n6, fill=bad]    {\textbf{9} pairs excluded};

		\begin{scope}[line width=1 pt, >=Stealth]
			\draw [->]   (n1.east) edge [pos=.8, "82"] (n4.west);
			\draw [->]   (n1.east) edge [pos=.8,"25", sloped] (n6.west);
			\draw [->]   (n1.east) edge [pos=.85,"5", sloped] (n7.west);
			
			\draw [->]   (n2.east) edge [pos=.8,"18"] (n5.west);
			\draw [->]   (n2.east) edge [pos=.6,"4", sloped] (n6.west);
			\draw [->]   (n2.east) edge [pos=.45,"2", sloped] (n7.west);
			
			\draw [->]   (n3.east) edge [pos=.2,"38"] (n6.west);
			\draw [->]   (n3.east) edge [pos=.5,"2", sloped] (n7.west);
			
		\end{scope}
	\end{tikzpicture}
	\caption{Diagram of what studies were downgraded or excluded for the sensitivity analysis.}
	\end{figure}

```

# Forest plot 

```{r forest, out.height="100%", fig.width=9, fig.height=12, fig.pos="ht", fig.cap="Forest plot of original and replication effect sizes. Original effect sizes are open dots, replication are closed dots. Coloring indicates subjective replication score, and p-original values are listed on the left side. "}

d |> 
  filter(target_d_calc < 5, rep_d_calc < 5) |>
  mutate(numpredInt=ifelse(predInt,1,0)) |> 
  ggplot(aes(y=reorder(target_lastauthor_year,target_d_calc, mean), color=as.factor(sub_rep)))+
    geom_vline(xintercept=0, linetype=3)+
  geom_point(aes(x=target_d_calc, shape="original"))+
  geom_point(aes(x=rep_d_calc, shape="replication"))+
  geom_segment(aes(x=target_d_calc, xend=rep_d_calc, y=target_lastauthor_year, yend=target_lastauthor_year))+
  scale_shape_manual(values=c("original"=21,"replication"=19), name=NULL)+
  coord_cartesian(xlim=c(-1.5,3.5))+
  geom_text(aes(x=-1.4, label=round(p_orig,3)), color="black", size=3, hjust=0, show.legend = F)+
  scale_color_viridis(discrete=T, direction = 1, 
                      name = "Subjective\nReplication\nSuccess\n")+theme_classic()+
  labs(x="Standardized Effect Size")+
  theme(axis.ticks.y=element_blank(), axis.title.y=element_blank())
```

# Additional model results
```{r}
do_draws <- function(model){
  draws <- model |> gather_draws(`b_[a-zA-Z_(): ]+`, regex=TRUE) |> 
    mutate(Term=str_sub(.variable, 3,-1) |> str_replace("M","_"), Estimate=.value) |>  filter(Term!="Intercept") |> 
    mutate(Term=factor(Term, levels=c("subfieldsocial", "subfieldother_psych", "subfieldnon_psych", "is_within", "single_vignette", "change_platform", "open_data", "open_mat", "stanford", "z_pub_year", "z_log_trials", "z_log_sample", "z_log_ratio_ss","z_log_p","z_target_d_calc"), labels=c("Social", "Other psych", "Non psych", "Within subjects", "Single vignette", "Switch to online", "Open data", "Open materials", "Stanford", "Publication year", "Log trials", "Log original sample size", "Log rep/orig sample", "P-value", "Original effect size"))) 
}

tier1_subjective <- read_rds(here(model_location, "tier1_subjective.rds")) |> do_draws() |> mutate(type="Without stats predictors") |> mutate(sens="All data")
tier2_porig <- read_rds(here(model_location, "tier2_porig.rds"))|> do_draws() |>  mutate(type="Without stats predictors") |> mutate(sens="All data")
tier2_predint <- read_rds(here(model_location, "tier2_predint.rds"))|> do_draws() |>  mutate(type="Without stats predictors") |> mutate(sens="All data")
tier3_subjective <- read_rds(here(model_location, "tier3_subjective.rds"))|> do_draws() |> mutate(type="Stats predictors") |> mutate(sens="All data")
tier3_porig <- read_rds(here(model_location, "tier3_porig.rds"))|> do_draws() |>  mutate(type="Stats predictors") |> mutate(sens="All data")
tier3_predint <- read_rds(here(model_location, "tier3_predint.rds"))|> do_draws() |>  mutate(type="Stats predictors") |> mutate(sens="All data")

sens1_subjective <- read_rds(here(model_location, "sens_tier1_subjective.rds"))|> do_draws() |> mutate(type="Without stats predictors") |> mutate(sens="Sensitivity test")
sens2_porig <- read_rds(here(model_location, "sens_tier2_porig.rds"))|> do_draws() |> mutate(type="Without stats predictors")|> mutate(sens="Sensitivity test")
sens2_predint <- read_rds(here(model_location, "sens_tier2_predint.rds"))|> do_draws() |> mutate(type="Without stats predictors")|> mutate(sens="Sensitivity test")
sens3_subjective <- read_rds(here(model_location, "sens_tier3_subjective.rds"))|> do_draws()|> mutate(type="Stats predictors")|> mutate(sens="Sensitivity test")
sens3_porig <- read_rds(here(model_location, "sens_tier3_porig.rds"))|> do_draws()|> mutate(type="Stats predictors")|> mutate(sens="Sensitivity test")
sens3_predint <- read_rds(here(model_location, "sens_tier3_predint.rds"))|> do_draws()|> mutate(type="Stats predictors")|> mutate(sens="Sensitivity test")

subjective <- tier1_subjective |> union(tier3_subjective) |> union(sens1_subjective) |> union(sens3_subjective)
porig <- tier2_porig |> union(tier3_porig) |> union(sens2_porig) |> union(sens3_porig)
predint <- tier2_predint |> union(tier3_predint) |> union(sens2_predint) |> union(sens3_predint)
```

```{r sub-results, out.height="75%", fig.width=8, fig.height=8, fig.pos="ht", fig.cap="Coefficient estimates and uncertainty from ordinal models predicting subjective replication scores. Solid lines correspond to models run on as much of the data as possible; dashed lines are on the subset of the data for sensitivity analysis. Red is run on all relevant data with experimental predictors only; blue is on relevant data where there are statistical predictors."}

  subjective |> ggplot(aes(y = reorder(Term, Estimate, mean), x = Estimate, color=type, linetype=sens, shape=sens)) + geom_vline(xintercept=0)+
    scale_shape_manual(values = c(19,21))+
  scale_color_solarized()+
  stat_pointinterval(position=position_dodge(width=.7))+labs(y="", x="Estimate, 66%, 95% CrI predicting subjective replication score", color="", linetype="", shape="")+theme(axis.text=element_text(size=11),legend.position="bottom")

```

```{r predint-results, out.height="75%", fig.width=8, fig.height=8, fig.pos="ht", fig.cap="Coefficient estimates and uncertainty from logistic models predicting prediction intervals. Solid lines correspond to models run on as much of the data as possible; dashed lines are on the subset of the data for sensitivity analysis. Red is run on all relevant data with experimental predictors only; blue is on relevant data where there are statistical predictors."}

  predint |> ggplot(aes(y = reorder(Term, Estimate, mean), x = Estimate, color=type, linetype=sens, shape=sens)) + geom_vline(xintercept=0)+
    scale_shape_manual(values = c(19,21))+
  scale_color_solarized()+
  stat_pointinterval(position=position_dodge(width=.7))+labs(y="", x="Estimate, 66%, 95% CrI predicting prediction interval", color="", linetype="", shape="")+theme(axis.text=element_text(size=11),legend.position="bottom")

```

```{r porig-results, out.height="75%", fig.width=8, fig.height=8, fig.pos="ht", fig.cap="Coefficient estimates and uncertainty from linear models predicting p-original values. Solid lines correspond to models run on as much of the data as possible; dashed lines are on the subset of the data for sensitivity analysis. Red is run on all relevant data with experimental predictors only; blue is on relevant data where there are statistical predictors."}

  porig |> ggplot(aes(y = reorder(Term, Estimate, mean), x = Estimate, color=type, linetype=sens, shape=sens)) + geom_vline(xintercept=0)+
    scale_shape_manual(values = c(19,21))+
  scale_color_solarized()+
  stat_pointinterval(position=position_dodge(width=.7))+labs(y="", x="Estimate, 66%, 95% CrI predicting p-original values", color="", linetype="", shape="")+theme(axis.text=element_text(size=11),legend.position="bottom")

```

# tau**2  sensitivity analysis is a mess

```{r, include=F, echo=F}
library(Replicate)
do_pred_int <- function(target_ES, target_SE, rep_ES, rep_SE){
  if(!is.na(target_ES)&!is.na(rep_ES)&!is.na(target_SE)&!is.na(rep_SE)){
    return(Replicate::pred_int(target_ES, target_SE**2, rep_ES, rep_SE**2)$rep.inside)
  }
  return(NA)
}

do_pred_int_sens <- function(target_ES, target_SE, rep_ES, rep_SE){
  if(!is.na(target_ES)&!is.na(rep_ES)&!is.na(target_SE)&!is.na(rep_SE)){
    yio=target_ES
    vio=target_SE**2
    yir=rep_ES
    vir=rep_SE**2
    t2=.21**2
    pooled.SE = sqrt(vio + vir + t2)
    PILo.sens = yio - qnorm(0.975) * pooled.SE
    PIHi.sens = yio + qnorm(0.975) * pooled.SE
    PIinside.sens = (yir > PILo.sens) & (yir < PIHi.sens)
    return(PIinside.sens)
  }
  return(NA)
}
do_p_orig <- function(target_ES, target_SE, rep_ES, rep_SE){
  if(!is.na(target_ES)&!is.na(rep_ES)){
    return(Replicate::p_orig(target_ES, target_SE**2,rep_ES, t2=0, rep_SE**2))
  }
  return(NA)
}

do_p_orig_sens <- function(target_ES, target_SE, rep_ES, rep_SE){
  if(!is.na(target_ES)&!is.na(rep_ES)){
    return(Replicate::p_orig(target_ES, target_SE**2,rep_ES, t2=0.21**2, rep_SE**2))
  }
  return(NA)
}
check_sens <- d |> filter(include=="stats") |>
  mutate(sens_target_d=target_d_calc,
         sens_target_se=target_SE*target_d_calc/target_ES,
         sens_target_se2=4/target_N+target_d_calc**2/(2*target_N),
         sens_rep_d=rep_d_calc,
         sens_rep_se=rep_SE*rep_d_calc/rep_ES,
         sens_target_se2=4/replication_N+rep_d_calc**2/(2*replication_N)) |>

  rowwise() |>
  mutate(predInt2 = do_pred_int(sens_target_d, sens_target_se, sens_rep_d, sens_rep_se),
         p_orig2 = do_p_orig(sens_target_d, sens_target_se, sens_rep_d, sens_rep_se),
         predIntSens=do_pred_int_sens(sens_target_d, sens_target_se, sens_rep_d, sens_rep_se),
         p_origSens=do_p_orig_sens(sens_target_d, sens_target_se, sens_rep_d, sens_rep_se))


check_sens |> select(starts_with("sens"))
check_sens |> #select(predInt, predInt2, predIntSens, p_orig, p_orig2, p_origSens) |>
  filter(signif(p_orig,2)!=signif(p_orig2,2)) |> View()

check_sens |> group_by(predIntSens) |> tally()
check_sens |> group_by(predInt2) |> tally()
check_sens |> group_by(predInt) |> tally()

check_sens |> ungroup() |> summarize(m=median(p_origSens))
check_sens |> ungroup() |> summarize(m=median(p_orig2))
check_sens |> ungroup() |> summarize(m=median(p_orig))


check_sens |> mutate(r1=sens_target_d/target_ES, r2=sens_target_se/target_SE, r3=sens_rep_d/rep_ES, r4=sens_rep_se/rep_SE) |> select(r1,r2,r3,r4)

d |> select(replication_raw_stat, target_raw_stat, include, sensitivity) |> View()
```