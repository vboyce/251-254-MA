---
title: PUT YOUR TITLE HERE
author:
  - name: Veronica Boyce
    affiliation: Stanford
    footnote:
      - corresp
  - name: Maya Mathur
    affiliation: Stanford
  - name: Michael C. Frank
    affiliation: Stanford
address:
  - code: Stanford
    address: Stanford University
footnote:
  - code: corresp
    text: "Corresponding author. Email: vboyce@stanford.edu"
bibliography: ["mybibfile.bib"] # Replace with one or more of your own bibtex files. Better BibTeX for Zotero is your friend
csl: dmk-format.csl # Use any CSL style. See https://www.zotero.org/styles for a good list. Ignored if citation_package: natbib
link-citations: TRUE
output:
  bookdown::pdf_document2:
    toc: FALSE
    keep_tex: TRUE
    template: generic_article_template.tex
    #md_extensions: "-autolink_bare_uris"
    number_sections: TRUE
    citation_package: default # Can also be "natbib"
lang: en # Main document language in BCP47 format
geometry: "margin=25mm"
papersize: a4
#linestretch: 2 # for double spacing
endfloat: FALSE # Set to TRUE to turn on latex endfloat package to place figures and tables at end of document
# endfloatoption: # See endfloat documentation for more possibilities
#   - tablesfirst # Default
#   - nomarkers # Default
numberlines: FALSE
authblk: TRUE # FALSE = author affiliations in footnotes; TRUE = author affiliations in a block below author names
footnotehyper: FALSE # TRUE will give you enhanced table footnote capabilities. Set to FALSE to be able to use French blocks. Needed due to what appears to be a latex bug.
urlcolor: blue
linkcolor: blue
citecolor: blue
graphics: TRUE # Needed to be able to include images
tables: TRUE # Needed to be able to include tables
# fancyhdr:
#   first:
#     #headleft: "REPORT-NO-XXXX"
#     headright: "Kaplan et al. (2021)"
#     headrulewidth: 0pt
#     #footleft: A left foot
#     footrulewidth: 0pt
#   subsequent:
#     #headleft: "NEXT-PAGE-HEADER-LEFT"
#     headright: "Kaplan et al. (2021)"
#     headrulewidth: 1pt
#     footrulewidth: 0pt

header-includes:
 - \usepackage{setspace}\singlespacing
 - \renewcommand{\textfraction}{0.00}
 - \renewcommand{\topfraction}{1}
 - \renewcommand{\bottomfraction}{1}
 - \renewcommand{\floatpagefraction}{1}
 - \setcounter{topnumber}{3}
 - \setcounter{bottomnumber}{3}
 - \setcounter{totalnumber}{4}

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE) # By default, hide code; set to TRUE to see code
#knitr::opts_chunk$set(fig.pos = 'th') # Places figures at top or here
knitr::opts_chunk$set(out.width = '100%', dpi=300,
                      fig.width=8, fig.width=8) # Figure resolution and size
knitr::opts_chunk$set(fig.env="figure") # Latex figure environment

options(knitr.table.format="latex") # For kable tables to work without setting format option

knitr::opts_chunk$set(echo=F, warning=F, message=F)#dev = "png", dev.args = list(type = "cairo-png")
 library("papaja")
library("bookdown")
library("rticles")
 library(here)
 library(tidyverse)
library(patchwork)
 library(brms)
 library(lme4)
 library(tidybayes)
 library(mgcv)
 library(cowplot)
 library(gridExtra)
library(broom.mixed)
library(tidymv)
library(mgcViz)
library(kableExtra)
#r_refs("r-references.bib", append=F)
theme_set(theme_bw())
options(knitr.table.format = "pdf")

model_location="code/models"
```

<!---------------------- Abstract --------------------->

::: {.abstract data-latex="" lang=en}
TODO abstract
:::

<!-- Use class keywords to format keywords section -->
::: {.keywords data-latex="" lang=en}
One keyword; Yet another keyword
:::

<!------------ Main text -------------------->


```{r, eval=F}
f <- googledrive::as_dribble("https://docs.google.com/spreadsheets/d/1UT6KLRujn6iEQ_s01_4yNfFYqc7hAWTpB-t9mdDp0O8/edit#gid=0")
googledrive::drive_download(f, path=here("data","raw_data.xlsx"), overwrite=T)

```

# TODO list
- need to do supplement with the stuff we preregistered (sensitivity analysis, all models)
- somewhere need discussion of how nobody is estimating p(true), but we're just more honest about it 
- meanings and codings of predictors (perhaps copied from pre-reg) should go in methods
- how to introduce coding methods
# introduction

[replication: it's a hot issue and concerns around replication have done a lot, see crisis/revolution] Replication is a hot topic. Some argue that it is a cornerstone of a cumulative science, and findings of low replication rates are a problem. 

[ there is controversy here, but to even discuss it, we need empirics] Even those who argue that replication is not so essential still rely on data from replications to make their cases that replication rates are not as low as they seem and that these replication rates are acceptable. 

[ there's ... not a lot of empirics] However, due to the arduous nature of collecting samples of replications, there have not been many large-scale replication efforts, so all of the argumentation around predictors of replications and field-wide replication rates is fit to a small number of data points. 

Many replications of individual effects have been performed, but these are less useful as pattern analysis because the varied sampling and reporting, and the fact they aren't all in one place. Also pub bias. 

We are aware of three large-scale replication efforts replicating experimental results in the existing psychology literature. The first is RP:P, which sampled roughly 100 studies from top psychology journals in 2008. They found an overall replication rate around 40%, which provided evidence to support growing concerns about the non-reliability of the literature. [idk, maybe worth framing that this was a big deal study when it came out]. TODO some discussion of how many papers have reanalysed this cutting the data different ways. 

The ManyLabs series of studies have also done large-scale replications of effects from psychology. Due to their primary goal of investigating different forms of hetereogeneity, their sampling has been non-representive, focussing on short studies with only two conditions. Across Many labs 1-3 foo bar replicated. Many labs 5 was a re-replicaiton attempt on 10 of RP:P and rescued 2/10. 

Camerer replicated the 21 behaviors studies published in Nature and Science from 2010-2015 that did not require special populations or special equipment. They found a roughly 60% replication rate. 

In addition to determining estimated overall replicaiton rates for fields and journals, there's also merit in knowing what features of experiments (and replication attempts) are predictive of replication success. Blah blah stakeholders and resources. There's some signal here, as people are able to predict replication success at above chance CITATIONS. RP:P looked at how replication rates varied across subsamples of their studies. They found that cognitive psychology studies replicated at higher, but still low rates (50% v 25%) compared to social psychology. They also found that larger effect sizes and smaller p-values of original studies were predictive of replicating. TODO do we talk about any other correlates. There are reasons to believe that experimental factors such as number of items or between and within subject designs may also be predictive (cite our old paper), and could pontentially be some of the reason for subfield differences. 

Here we introduce a new dataset of replications in the behavioral sciences, primarily psychology. Over the years 2011-2022, students in a graduate-level experimental methods class have conducted online replications as individual course projects. From this, we have 176 experimental replications that were codeable. This approximately doubles the set of experiments in the large-scale replication literature. We investigate predictors of replicability in this new dataset. 

## quick methods
Class, taught by last author, is aimed at first-year graduate students, but taken by ... Since around 2015, it has been required for incoming PhD students in the Psychology Department. Over the course of a quarter long class, students work through their individual replication projects, from choosing a study, to reimplementing it, to creating analysis code, piloting the study, pre-registering it, and finally running a full data collection and writing up their results. Students are free to choose studies related to their interests, although recent articles from Psychological Science are the recommended path under uncertainty (leading to a high proportion of Psych science articles in this replication sample). While the sampling procedure is non-random, it is generally representative of studies that are of interest to and doable by first year grad students. 

Studies vary along a number of dimensions, including statistical properties, subfield, and experimental properties. We leverage this naturally occurring variation to see if these properties predict replication success. 

# results

As our primary outcome measure, we use a subjective measure of replication success. At the end of the class, the instruction team coded each project on a 0-1 scale indicating whether or not it replicated. This allows for nuance around marginal effects, covers studies with a broad range of statistical outcomes (including those that do not lend themselves to NHST), and includes studies with multiple important outcome measures. For robustness, first author independently coded all projects on the same scale off of the final write-ups. Disagreements (which occured foobar % of the time) were resolved by discussion between first and third authors. 

Over the years, there have been a number of student projects, of these we are able to include foobar (see PRISMA). Because of variance in the experimental designs and reporting practices, we have variable statistical information. To address this, we conducted a series of models, balancing between including as many data points as possible, and including potentially relevant outcome and predictor variables. Here we focus on one set of models, the prediction of subjective replication outcome on the basis of the whole dataset without the statistical predictors. Other model results, including those from a sensitivity analysis, are avaiable in the supplement. 


# Acknowledgements {-}

Acknowledge people here. `{-}` useful to not number this section.

# References {-}

<!-- Use this magic to place references here. -->
<div id="refs"></div>

# (APPENDIX) Appendices {-}

<!-- The above header does not appear in output. Not exactly sure why. -->

# Appendix A {-}

Some appendix text.

# Appendix B {-}

More appendix text.
