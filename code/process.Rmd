---
title: "251 MA"
output:
  html_document: 
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=F, message=F)
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
options(knitr.table.format = "html")
knitr::opts_chunk$set(echo = F)
library(tidyverse)
library(viridis)
library(Replicate)
library(metafor)
library
theme_set(theme_bw())
```

# TODOs
- why are some ES's  about 2 times bigger than they should be?
- get ES from t test, from F test (using compute es) < -- what does within_one and within_two mean??
- validate df against num people?
- what about for other test statistics (r)

# Pull data

```{r, eval=F}
library(googledrive)

f <- googledrive::as_dribble("https://docs.google.com/spreadsheets/d/1UT6KLRujn6iEQ_s01_4yNfFYqc7hAWTpB-t9mdDp0O8/edit#gid=0")
googledrive::drive_download(f, path="raw_data.xlsx", overwrite=T)

```

```{r}
d <- readxl::read_xlsx("raw_data.xlsx", sheet="aligned data", skip=1) |> 
  
  select(target_lastauthor_year, status, academic_year, subfield, target_year, stanford_internal, 
         open_data, open_materials, target_on_turk, replication_on_turk, 
         within_between, single_vignette, repeated_measure,
         target_N, target_test, target_raw_stat, target_pvalue, target_ES_type, target_ES_value,
         replication_N, replication_test, replication_raw_stat, replication_pvalue, replication_ES_type, replication_ES_value,
         replicated_instructor_code, replicated_report_code)

```

# Exclusions

```{r}
d |> group_by(status) |> tally()

d |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |> tally()
```
# Validation

```{r}
d_val <- d |> filter(!status %in% c("missing", "non-experiment", "reproduction"))

# d_val$academic_year |> unique()
# 
# d_val |> filter(!subfield %in% c("social","cognitive","non-psych","other-psych"))
# 
# d_val |> filter(!stanford_internal %in% c("no","yes"))
# 
# d_val |> filter(!open_data %in% c("no","yes"))
# 
# d_val |> filter(!open_materials %in% c("no","yes"))
# 
# d_val |> filter(!target_on_turk %in% c("no","yes"))
# 
# d_val |> filter(!replication_on_turk %in% c("no","yes"))
# 
# d_val |> filter(!within_between %in% c("within","between","mixed"))
# 
# d_val |> filter(!single_vignette %in% c(0,1))





```

# Parsing

We parse out values from (for now) t tests and F tests (other tests to be added later). 

```{r}
# considered using the effectsize package but afaik we don't care about estimating CI's here and there were optim problems with that

parse_t <- function(tval, within_between) {
  df=str_extract(tval, "\\(.*\\)") |> str_sub(2,-2) |> as.numeric()
  val=str_extract(tval, "=.*") |> str_sub(2,-1) |> as.numeric() |> abs()
  pval=pt(q=val, df=df, lower.tail=FALSE)*2
  d_calc=NA
  if(within_between=="between"){
    d_calc=2*val/(sqrt(df))  # note this uses the 2t/sqrt(df) approximation df+2 might be more appropriate? 
  }
  else{d_calc=val/sqrt(df)}
  return(data.frame("df_1"=NA, "df_2"=df,"tstat"=val, "fstat"=NA, "p_calc"=pval, "d_calc"=d_calc))
}

parse_f <- function(fval, within_between){
  df_1 =str_extract(fval, "\\(.*,") |> str_sub(2,-2) |> as.numeric()
  df_2 =str_extract(fval, ",.*\\)") |> str_sub(2,-2) |> as.numeric()
  val=str_extract(fval, "=.*") |> str_sub(2,-1) |> as.numeric() |> abs()
  pval=pf(q=val, df1=df_1, df2=df_2, lower.tail=FALSE)
  d_calc=NA
  if(!is.na(df_1)&&df_1==1){
    if(within_between=="between"){
      d_calc=2*sqrt(val)/sqrt(df_2) # if there's just two groups, then F=t**2 and we can use the t-test thingy
    }
    else{
      d_calc=sqrt(val)/sqrt(df_2)
    }
  if(!is.na(df_1)){
    # we go through partial eta
    n=df_1+df_2+1 # rederive n b/c it's not always matching the n we have
    partial_eta=(val*df_1)/(val*df_1+df_2)
    d_calc=sqrt(n/(n-1)*(partial_eta/(1-partial_eta)))
  }
}
  return(data.frame("df_1"=df_1,"df_2"=df_2,"tstat"=NA, "fstat"=val, "p_calc"=pval, "d_calc"=d_calc))
}

do_blanks <- function(){
  return(data.frame("df_1"=NA,"df_2"=NA,"tstat"=NA, "fstat"=NA, "p_calc"=NA, "d_calc"=NA))
}
do_parsing=function(raw_stat, within_between){
  if (is.na(raw_stat)) {return (do_blanks())}
  if (str_sub(raw_stat,1,1)=="t"){return(parse_t(raw_stat, within_between))}
  if (str_sub(raw_stat,1,1)=="F"){return(parse_f(raw_stat, within_between))}
  return (do_blanks())
}
```


```{r}
test <- d_val |> 
  mutate(target=map2(target_raw_stat, within_between, do_parsing),
         rep=map2(replication_raw_stat, within_between, do_parsing)) |> 
  unnest(cols=c(target, rep), names_sep="_")
                       
  
```

Comparing calculated p vals to provided (or hand calculated) ones.

```{r}

ggplot(test, aes(x=target_pvalue, y=target_p_calc))+geom_point()+geom_abline(slope=1,intercept=0)+
  scale_x_log10()+scale_y_log10()

ggplot(test, aes(x=replication_pvalue, y=rep_p_calc))+geom_point()+geom_abline(slope=1,intercept=0)+scale_x_log10()+scale_y_log10()

```
Comparing calculated ES to original (or hand calculated) ES. All converted to SMD. 

Note: black line is y=x, red line is y=2x. Things on y=2x probably had issues where one of the tests calculated it as (within|between) and the other did it the other way. 

```{r}
fill_es <- function(type, value, n){
  if (is.na(type)) {
    return(NA)}
  if (is.na(value)) {
    return(NA)
  }
  if (type=="partial eta sq"){
    d = sqrt( (n-1)/n * abs(value)/(1-abs(value)))
    if (value < 0) {
      return(-d)}
    return(d)
    }
  if (type %in% c("d", "SMD")){
    return(abs(value))
  }
  return(NA)
}

test |> rowwise() |> mutate(d_fill_target=fill_es(target_ES_type, target_ES_value, target_N))|> 
  ggplot(aes(x=d_fill_target, y=target_d_calc))+geom_point()+geom_abline(slope=1,intercept=0)+geom_abline(slope=2,intercept=0, color="red")+coord_cartesian(xlim=c(0,5),ylim=c(0,5))

test |> rowwise() |> mutate(d_fill_rep=fill_es(replication_ES_type, replication_ES_value, replication_N))|>
  ggplot(aes(x=d_fill_rep, y=rep_d_calc))+geom_point()+geom_abline(slope=1,intercept=0)+geom_abline(slope=2,intercept=0, color="red")

```



# Are the ES's okay?

```{r}
library(metafor)


est_SE <- function(p,d){
  z <- -.862+sqrt(abs(.743-2.404*log(p)))
  SE <- abs(d/z)
  return(SE)
}

d_es <-  test |> 
  rowwise() |> 
  mutate(target_se_calc=est_SE(target_p_calc,target_d_calc),
         rep_se_calc=est_SE(rep_p_calc,rep_d_calc))

```

```{r}

d_es_try <- d_es |> filter(!is.na(target_d_calc)) |> 
  filter(!is.na(rep_d_calc)) |> 
  mutate(
         predInt=Replicate::pred_int(target_d_calc,target_se_calc**2, rep_d_calc, rep_se_calc**2)$rep.inside,
         p_orig=Replicate::p_orig(target_d_calc,target_se_calc**2, rep_d_calc, t2=0, rep_se_calc**2))
  
```

# PredInt and P_orig

```{r}

d_es_try |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=p_orig))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=F, direction=-1)+
  labs(color="p_orig", x="Original SMD", y="Replication SMD")

d_es_try |> mutate(p_sig=p_orig<.05) |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=p_sig))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)+
  labs(color="P_orig<.05", x="Original SMD", y="Replication SMD")

d_es_try |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=predInt))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)+
  labs(color="rep in predInt", x="Original SMD", y="Replication SMD")

d_es_try |> ggplot(aes(x=replicated_report_code, y=p_orig))+geom_jitter(height=0, alpha=.5)+
  #scale_y_log10()+
  geom_hline(yintercept=.05)

d_es_try |> ggplot(aes(x=replicated_report_code, y=predInt))+geom_jitter(alpha=.5)
```


# Prelim analysis -- Correlation between ES

There's that one ling paper with ES of 10+...

Might want to just hide that point or something instead...

Could weight by precision or something

```{r}
  
d_es |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=as.factor(replicated_report_code)))+
  geom_point()+
  #coord_cartesian(xlim=c(0,5), ylim=c(-1,5))+
  geom_abline(slope=1, intercept=0)+
  scale_color_viridis(discrete=T, direction=-1)

d_es |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=as.factor(replicated_report_code)))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)+
  labs(color="Replicated?", x="Original SMD", y="Replication SMD")
```

# How much missing data?

```{r, message=T}
message("total rows")
d |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |> nrow()

message("number of NAs per column")

d |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |> summarize(                                                      across(everything(),~sum(is.na(.)))) |>
pivot_longer(everything()) |>
  arrange(desc(value)) |>
  filter(value!=0)


```

# Correlation between replication scores


```{r, message=T}
d_corr <- d |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |>
  mutate(replicated_instructor_code=as.numeric(replicated_instructor_code)) |> #forcibly convert the ?s to NAs
  filter(!is.na(replicated_instructor_code) & !is.na(replicated_report_code))

corr <- cor.test(d_corr$replicated_instructor_code, d_corr$replicated_report_code, method = 'spearman')

message("Num not match")
d_corr |> filter(replicated_instructor_code!=replicated_report_code) |> nrow()

message("Num match")
d_corr |> filter(replicated_instructor_code==replicated_report_code) |> nrow()

message("distribution of non-matches")

ggplot(d_corr |> filter(replicated_instructor_code!=replicated_report_code), aes(x=replicated_instructor_code, y=replicated_report_code))+geom_jitter(width=.04, height=.04)+theme_bw()

d_corr |>
  group_by(replicated_instructor_code, replicated_report_code ) |> tally() |> arrange(replicated_report_code) |>
  pivot_wider(names_from=replicated_report_code, values_from=n, values_fill=0)
```

# code vars for models

NOTE: will need to replace replicated_code with the discussion agreed one!!

## demographics


```{r}
d_demo <- d_es |> 
  ungroup() |> 
  mutate(pub_year= target_year-mean(target_year)) |> 
  select(target_year, pub_year, subfield, replicated_report_code, academic_year)

summary(d_demo)
d_demo |> group_by(subfield) |> tally()
```

## statistics

? will outliers on ratio_ss cause a problem?

```{r}
d_stats <- d_es |> 
  mutate(log_p =log(target_p_calc),
         log_sample =log(target_N),
         ratio_ss = replication_N/target_N,
         change_platform=ifelse(replication_on_turk==target_on_turk,0,1)) |> 
  #this codes 1 if the original was in person, but replication turk/prolific,
  # 0 if they were both on turk/prolific or both in-person (rare, but happens a few times)
  select(replicated_report_code,log_p,log_sample, ratio_ss, change_platform, academic_year, target_d_calc)

summary(d_stats)
```

## closeness

```{r}

# could do with mutate across, but clearer this way?

d_close <- d_es |> 
  mutate(open_data=ifelse(open_data=="yes", 1,0),
         open_mat=ifelse(open_materials=="yes", 1,0),
         stanford=ifelse(stanford_internal=="yes", 1,0)) |> 
  select(open_data, open_mat, stanford, replicated_report_code,
         academic_year)

summary(d_close)
```

## design


```{r}
d_design <- d_es |> 
  mutate(is_within=case_when(
    within_between=="within" ~ 1,
    within_between=="mixed" ~ 1,
    within_between=="between" ~ 0),
    log_trials=log(repeated_measure),
    log_sample=log(target_N))|> 
  select(is_within, single_vignette,log_trials, log_sample, replicated_report_code, academic_year)

summary(d_design)
```