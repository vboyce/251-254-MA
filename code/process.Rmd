---
title: "251 MA"
output:
  html_document: 
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning=F, message=F)
knitr::opts_chunk$set(dev = "png", dev.args = list(type = "cairo-png"))
options(knitr.table.format = "html")
knitr::opts_chunk$set(echo = F)
library(tidyverse)
library(viridis)
library(Replicate)
library(metafor)
library(esc)
theme_set(theme_bw())
```


# Pull data


```{r, eval=F}
library(googledrive)

f <- googledrive::as_dribble("https://docs.google.com/spreadsheets/d/1UT6KLRujn6iEQ_s01_4yNfFYqc7hAWTpB-t9mdDp0O8/edit#gid=0")
googledrive::drive_download(f, path="raw_data.xlsx", overwrite=T)

```

```{r}
d <- readxl::read_xlsx("raw_data.xlsx", sheet="aligned data", skip=1) |> 
  
  select(target_lastauthor_year, status, academic_year, subfield, target_year, stanford_internal, 
         open_data, open_materials, target_on_turk, replication_on_turk, 
         within_between, single_vignette, repeated_measure,
         target_N, target_test, target_raw_stat, target_pvalue, target_ES_type, target_ES_value,
         same_dir,
         replication_N, replication_test, replication_raw_stat, replication_pvalue, replication_ES_type, replication_ES_value,
         replicated_instructor_code, replicated_report_code, adjudicated_replication_code)

```

# Exclusions

```{r}
d |> group_by(status) |> tally()

d |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |> tally()
```
We have maybe as many as 177 at least for some analyses. 

Descriptions: 

- "complete" -- it's a full case

- "adj" -- will be a full case once we get subjective replication and subfield coded

- "beta" -- don't have standardized ES, but have a pair that we can do predInt to

- "ES_direction" -- we don't have the direction coded (ex. is an interaction that I can't eyeball, or a multi-way F test with no graph)

- "ask" -- might be salvageable, but I have questions about coding

- "done" -- got as far as I can, and that is that we have demographics but not stats

- "unusable" -- got as far as I can, and it does not have complete descriptives

- "missing" -- student didn't finish or we don't have write-up

- "non-experiment" -- student replicated something that was not an experiment

- "reproduction" -- student did a reproduction and not replication 


```{r}
d_val <- d |> filter(!status %in% c("missing", "non-experiment", "reproduction"))

# d_val$academic_year |> unique()
# 
# d_val |> filter(!subfield %in% c("social","cognitive","non-psych","other-psych"))
# 
# d_val |> filter(!stanford_internal %in% c("no","yes"))
# 
# d_val |> filter(!open_data %in% c("no","yes"))
# 
# d_val |> filter(!open_materials %in% c("no","yes"))
# 
# d_val |> filter(!target_on_turk %in% c("no","yes"))
# 
# d_val |> filter(!replication_on_turk %in% c("no","yes"))
# 
# d_val |> filter(!within_between %in% c("within","between","mixed"))
# 
# d_val |> filter(!single_vignette %in% c(0,1))





```

# Parsing

We parse out values from the raw stats. 

```{r}
# considered using the effectsize package but afaik we don't care about estimating CI's here and there were optim problems with that

parse_t <- function(tval, within_between) {
  df=str_extract(tval, "\\(.*\\)") |> str_sub(2,-2) |> as.numeric()
  val=str_extract(tval, "=.*") |> str_sub(2,-1) |> as.numeric() |> abs()
  pval=pt(q=val, df=df, lower.tail=FALSE)*2
  d_calc=NA
  N_from_df=NA
  if(within_between=="between"){
    d_calc=2*val/(sqrt(df))  # note this uses the 2t/sqrt(df) approximation df+2 might be more appropriate? 
    N_from_df=df+2 # between so add 2
  }
  else{
    d_calc=val/sqrt(df)
    N_from_df=df+1
  }
  return(data.frame("df_1"=NA, "df_2"=df,"tstat"=val, "fstat"=NA, "p_calc"=pval, "d_calc"=d_calc, "N_calc"=N_from_df, "ES"=NA, "SE"=NA))
}
```

```{r}
parse_f <- function(fval, within_between){
  df_1 =str_extract(fval, "\\(.*,") |> str_sub(2,-2) |> as.numeric()
  df_2 =str_extract(fval, ",.*\\)") |> str_sub(2,-2) |> as.numeric()
  val=str_extract(fval, "=.*") |> str_sub(2,-1) |> as.numeric() |> abs()
  pval=pf(q=val, df1=df_1, df2=df_2, lower.tail=FALSE)
  d_calc=NA
  N_from_df=df_1+df_2+1
  if(!is.na(df_1)&&df_1==1){
    if(within_between=="between"){
      d_calc=2*sqrt(val)/sqrt(df_2) # if there's just two groups, then F=t**2 and we can use the t-test thingy
    }
    else{
      d_calc=sqrt(val)/sqrt(df_2)
    }
  }
  else if(!is.na(df_1)){
    # we go through partial eta
    n=df_1+df_2+1 # rederive n b/c it's not always matching the n we have
    partial_eta=(val*df_1)/(val*df_1+df_2)
    d_calc=sqrt(n/(n-1)*(partial_eta/(1-partial_eta)))
  }
  return(data.frame("df_1"=df_1,"df_2"=df_2,"tstat"=NA, "fstat"=val, "p_calc"=pval, "d_calc"=d_calc, "N_calc"=N_from_df, "ES"=NA, "SE"=NA))
}
```

```{r}
# for proportions 
#ex <- "prob: 13 / 14 , 2 / 14"
parse_prop <- function(propval){
  val <- str_extract_all(propval, "[0-9]+")[[1]]
  num1 <- val[1] |> as.numeric()
  den1 <- val[2] |> as.numeric()
  num2 <- val[3] |> as.numeric()
  den2 <- val[4] |> as.numeric()
  est1 <- num1/den1
  est1_var <- est1*(1-est1)/den1
  est2 <- num2/den2
  est2_var <- est2*(1-est2)/den2
  diff <- est1-est2
  diff_var <- est1_var+est2_var
  return(data.frame("df_1"=NA, "df_2"=NA,"tstat"=NA, "fstat"=NA, "p_calc"=NA, "d_calc"=NA, "N_calc"=NA, "ES"=diff, "SE"=sqrt(diff_var)))
}
#parse_prop(ex)


```

```{r}
parse_mean_ci <- function(mci,within_between,n){
  cond1=str_extract(mci, "m1.*\\],")
  cond2=str_extract(mci, "m2.*\\]")
  m1=str_extract(cond1, "m1=.*\\[") |> str_sub(4,-2) |> as.numeric()
  m2=str_extract(cond2, "m2=.*\\[") |> str_sub(4,-2) |> as.numeric()
  low1=str_extract(cond1, "\\[.*,.") |> str_sub(2,-3) |> as.numeric()
  low2=str_extract(cond2, "\\[.*,") |> str_sub(2,-2) |> as.numeric()
  high1=str_extract(cond1, ",.*\\]") |> str_sub(2,-2) |> as.numeric()
  high2=str_extract(cond2, ",.*\\]") |> str_sub(2,-2) |> as.numeric()
  se1=high1-low1/(2*1.96)
  se2=high2-low2/(2*1.96)
  se=(se1+se2)/2
  tval=(m1-m2)/se |> abs()
  if (within_between=="within"){
  df=n-1
  pval=pt(q=tval, df=df, lower.tail=FALSE)*2
  d_calc=tval/(sqrt(df)) 
  }
  else{
    df=NA
    pval=NA
    d_calc=NA
  }
  return(data.frame("df_1"=df,"df_2"=NA,"tstat"=tval, "fstat"=NA, "p_calc"=pval, "d_calc"=d_calc, "N_calc"=NA, "ES"=NA, "SE"=NA))
}
```

```{r}
parse_mean_sd <- function(msd,within_between,n){
  cond1=str_extract(msd, "m1.*\\),")
  cond2=str_extract(msd, "m2.*\\)")
  m1=str_extract(cond1, "m1=.*\\(") |> str_sub(4,-2) |> as.numeric()
  m2=str_extract(cond2, "m2=.*\\(") |> str_sub(4,-2) |> as.numeric()
  sd1=str_extract(cond1, "\\(.*\\),") |> str_sub(2,-3) |> as.numeric()
  sd2=str_extract(cond2, "\\(.*\\)") |> str_sub(2,-2) |> as.numeric()
  sd_pool=(sd1+sd2)/2
  se=sd_pool/sqrt(n)
  tval=(m1-m2)/se |> abs()
  if (within_between=="within"){
  df=n-1
  pval=pt(q=tval, df=df, lower.tail=FALSE)*2
  d_calc=tval/(sqrt(df)) 
  }
  else if (within_between=="between"){
    df=n-2
    pval=pt(q=tval, df=df, lower.tail=FALSE)*2
    d_calc=2*tval/sqrt(df)
  }
  else{
    df=NA
    pval=NA
    d_calc=NA
  }
  return(data.frame("df_1"=df,"df_2"=NA,"tstat"=tval, "fstat"=NA, "p_calc"=pval, "d_calc"=d_calc, "N_calc"=NA, "ES"=NA, "SE"=NA))
}


```

```{r}
parse_mean_se <- function(mse,within_between,n){
  cond1=str_extract(mse, "m1.*\\),")
  cond2=str_extract(mse, "m2.*\\)")
  m1=str_extract(cond1, "m1=.*\\(") |> str_sub(4,-2) |> as.numeric()
  m2=str_extract(cond2, "m2=.*\\(") |> str_sub(4,-2) |> as.numeric()
  se1=str_extract(cond1, "\\(.*\\),") |> str_sub(2,-3) |> as.numeric()
  se2=str_extract(cond2, "\\(.*\\)") |> str_sub(2,-2) |> as.numeric()
  se=(se1+se2)/2
  tval=(m1-m2)/se |> abs()
  if (within_between=="within"){
  df=n-1
  pval=pt(q=tval, df=df, lower.tail=FALSE)*2
  d_calc=tval/(sqrt(df)) 
  }
  else if (within_between=="between"){
    df=n-2
    pval=pt(q=tval, df=df, lower.tail=FALSE)*2
    d_calc=2*tval/sqrt(df)
  }
  else{
    df=NA
    pval=NA
    d_calc=NA
  }
  return(data.frame("df_1"=df,"df_2"=NA,"tstat"=tval, "fstat"=NA, "p_calc"=pval, "d_calc"=d_calc, "N_calc"=NA, "ES"=NA, "SE"=NA))
}

```


```{r}


parse_beta_se <- function(raw_stat){
    beta=str_extract(raw_stat, "b=.*\\(") |> str_sub(3,-2) |> as.numeric()
    se=str_extract(raw_stat, "\\(.*\\)") |> str_sub(2,-2) |> as.numeric()
    zval=beta/se
    pval=2*pnorm(zval, lower.tail=F)
return(data.frame("df_1"=NA,"df_2"=NA,"tstat"=NA, "fstat"=NA, "p_calc"=pval, "d_calc"=NA, "N_calc"=NA, "ES"=beta, "SE"=se))
}

```

```{r}

parse_beta_ci <- function(raw_stat){
  beta=str_extract(raw_stat, "b=.*\\[") |> str_sub(3,-2) |> as.numeric()
  low=str_extract(raw_stat, "\\[.*,") |> str_sub(2,-2) |> as.numeric()
  high=str_extract(raw_stat, ",.*\\]") |> str_sub(2,-2) |> as.numeric()
  se=high-low/(2*1.96)
  zval=beta/se
    pval=2*pnorm(zval, lower.tail=F)
  return(data.frame("df_1"=NA,"df_2"=NA,"tstat"=NA, "fstat"=NA, "p_calc"=pval, "d_calc"=NA, "N_calc"=NA, "ES"=beta, "SE"=se))
}

```

```{r}

do_blanks <- function(){
  return(data.frame("df_1"=NA,"df_2"=NA,"tstat"=NA, "fstat"=NA, "p_calc"=NA, "d_calc"=NA, "N_calc"=NA, "ES"=NA, "SE"=NA))
}
do_parsing=function(raw_stat, within_between,n){
  if (is.na(raw_stat)) {return (do_blanks())}
  if (str_sub(raw_stat,1,1)=="t"){return(parse_t(raw_stat, within_between))}
  if (str_sub(raw_stat,1,1)=="F"){return(parse_f(raw_stat, within_between))}
  if (str_sub(raw_stat,1,4)=="prop"){return(parse_prop(raw_stat))}
  if (str_sub(raw_stat, 1,3)=="MCI"){return(parse_mean_ci(raw_stat, within_between,n))}
  if (str_sub(raw_stat, 1,3)=="MSD"){return(parse_mean_sd(raw_stat, within_between,n))}
  if (str_sub(raw_stat, 1,3)=="MSE"){return(parse_mean_se(raw_stat, within_between,n))}
  if (str_sub(raw_stat, 1,8)=="wilcoxon"){return(parse_wilcoxon(raw_stat))}
  if (str_sub(raw_stat, 1,3)=="bse"){return(parse_beta_se(raw_stat))}
  if (str_sub(raw_stat, 1,3)=="bci"){return(parse_beta_ci(raw_stat))}

  return (do_blanks())
}
```


```{r}
fill_es <- function(type, value, n){
  if (is.na(type)) {
    return(NA)}
  if (is.na(value)) {
    return(NA)
  }
  if (type=="partial eta sq"){
    d = sqrt( (n-1)/n * abs(value)/(1-abs(value)))
    return(d)
    }
  if (type %in% c("d", "SMD")){
    return(abs(value))
  }
  return(NA)
}

test <- d_val |> 
  mutate(target_raw_stat=gsub(" ","",target_raw_stat),
         target=pmap(list(target_raw_stat, within_between,target_N), do_parsing),
         replication_raw_stat=gsub(" ","",replication_raw_stat),
         rep=pmap(list(replication_raw_stat, within_between,replication_N), do_parsing)) |> 
  unnest(cols=c(target, rep), names_sep="_") |> 
  rowwise() |> 
  mutate(d_fill_target=fill_es(target_ES_type, target_ES_value, target_N),
         d_fill_rep=fill_es(replication_ES_type, replication_ES_value, replication_N)) 
                       
  
```

## Compare pvals

Comparing calculated p vals to provided (or hand calculated) ones. Line is x=y. 

These look pretty reasonable. Lots on the line and others is places were <.001's happened. 

It may be worth checking points that are above the line. 

```{r}

ggplot(test, aes(x=target_pvalue, y=target_p_calc))+geom_point()+geom_abline(slope=1,intercept=0)+
  scale_x_log10()+scale_y_log10()

ggplot(test, aes(x=replication_pvalue, y=rep_p_calc))+geom_point()+geom_abline(slope=1,intercept=0)+scale_x_log10()+scale_y_log10()

```

## Compare ES 

Comparing calculated ES to original (or hand calculated) ES. All converted to SMD. 

Note: black line is y=x, red line is y=2x. Things on y=2x probably had issues where one of the tests calculated it as (within|between) and the other did it the other way. 

```{r}


test |> 
  ggplot(aes(x=d_fill_target, y=target_d_calc))+geom_point()+geom_abline(slope=1,intercept=0)+geom_abline(slope=2,intercept=0, color="red")+coord_cartesian(xlim=c(0,5),ylim=c(0,5))+geom_abline(slope=.5,intercept=0, color="red")

test |> 
  ggplot(aes(x=d_fill_rep, y=rep_d_calc))+geom_point()+geom_abline(slope=1,intercept=0)+geom_abline(slope=2,intercept=0, color="red")+geom_abline(slope=.5,intercept=0, color="red")

```


Where there's a difference, I could check whether it's being compared to something *I* calculated versus something that an original paper or students paper calculated? Except that there's sources for errors in any of those. Ones where we get an off  by two error -- should I double check within-betweeness for the test? 

## what didn't parse

these are ones where we did not get a non-NA effect size. Could be due to formulas being incomplete, or missing information. 

note that we also aren't including the betas where we know we can't get effect size, but we'll still get porig and predInt. 

```{r}

test |> filter(is.na(target_d_calc)&is.na(target_beta)) |> filter(!is.na(target_raw_stat)) |>  pull(target_raw_stat)

test |> filter(is.na(rep_d_calc)&is.na(rep_beta)) |> filter(!is.na(replication_raw_stat)) |> pull(replication_raw_stat)
```

## how are the df's lining up with sample size?

We can try to back out effective sample size from the df's. Note that we don't always expect them to agree (Welch's t test, repeated measures, comparisons only on a sample), but still useful to look at.

There's a lot of off by 1 or 2 things, which I'm unsure what to make of. (As much as possible both sample size and test stats are taken from the papers directly)

```{r}
 test |> filter(!is.na(target_N_calc)) |> select(target_N_calc, target_N, target_raw_stat, within_between, target_lastauthor_year) |>
  mutate(diff=target_N_calc-target_N) |> 
  ggplot(aes(x=target_N, y=target_N_calc, color=(target_N==target_N_calc)))+geom_point()+geom_abline(slope=1, intercept=0)+scale_y_log10()+scale_x_log10()+scale_color_manual(values=c("TRUE"="black","FALSE"="red"))

 test |> filter(!is.na(rep_N_calc)) |> select(rep_N_calc, replication_N, replication_raw_stat, within_between, target_lastauthor_year) |> mutate(diff=rep_N_calc-replication_N) |> 
   ggplot(aes(x=replication_N, y=rep_N_calc, color=(replication_N==rep_N_calc)))+geom_point()+geom_abline(slope=1, intercept=0)+scale_y_log10()+scale_x_log10()+scale_color_manual(values=c("TRUE"="black","FALSE"="red"))


```

# PredInt and P_orig

```{r}
library(metafor)


est_SE <- function(p,d){
  z <- -.862+sqrt(abs(.743-2.404*log(p)))
  SE <- abs(d/z)
  return(SE)
}

d_es <-  test |> 
  rowwise() |> 
  mutate(target_se_calc=est_SE(target_p_calc,target_d_calc),
         rep_d_calc=ifelse(same_dir=="no", -rep_d_calc, rep_d_calc),
         rep_se_calc=est_SE(rep_p_calc,rep_d_calc))

```

```{r}
do_pred_int <- function(target_d_calc, target_se_calc, rep_d_calc,rep_se_calc, target_beta, target_SE, rep_beta, rep_SE){
  if (!is.na(target_d_calc)&!is.na(rep_d_calc)){
    return(Replicate::pred_int(target_d_calc,target_se_calc**2, rep_d_calc, rep_se_calc**2)$rep.inside)}
  if(!is.na(target_beta)&!is.na(rep_beta)){
    return(Replicate::pred_int(target_beta, target_SE**2, rep_beta, rep_SE**2)$rep.inside)
  }
  return(NA)
}

do_p_orig <- function(target_d_calc, target_se_calc, rep_d_calc,rep_se_calc, target_beta, target_SE, rep_beta, rep_SE){
  if (!is.na(target_d_calc)&!is.na(rep_d_calc)){
    return(Replicate::p_orig(target_d_calc,target_se_calc**2, rep_d_calc, t2=0, rep_se_calc**2))}
  if(!is.na(target_beta)&!is.na(rep_beta)){
    return(Replicate::p_orig(target_beta, target_SE**2,rep_beta, t2=0, rep_SE**2))
  }
  return(NA)
}

do_subjective_rep <- function(replicated_instructor_code, replicated_report_code, adjudicated_replication_code){
  if (is.na(replicated_instructor_code)){return(as.numeric(NA))}
  if (is.na(replicated_report_code)){return(as.numeric(NA))}
  if (replicated_instructor_code==replicated_report_code){ return(replicated_instructor_code)}
  if (!is.na(adjudicated_replication_code)){return (adjudicated_replication_code)}
  return(as.numeric(NA))
}
d_es_predInt <- d_es |> 
         mutate(
           predInt=do_pred_int(target_d_calc, target_se_calc, rep_d_calc,rep_se_calc, target_beta, target_SE, rep_beta, rep_SE),
           p_orig=do_p_orig(target_d_calc, target_se_calc, rep_d_calc,rep_se_calc, target_beta, target_SE, rep_beta, rep_SE),
           sub_rep= do_subjective_rep(replicated_instructor_code, replicated_report_code, adjudicated_replication_code))
           
           
                
              
```


```{r}

d_es_predInt |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=p_orig))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=F, direction=-1)+
  labs(color="p_orig", x="Original SMD", y="Replication SMD")

d_es_predInt |> mutate(p_sig=p_orig<.05) |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=p_sig))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)+
  labs(color="P_orig<.05", x="Original SMD", y="Replication SMD")

d_es_predInt |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=predInt))+
  geom_point()+
  coord_cartesian(xlim=c(0,2), ylim=c(-1,3))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)+
  labs(color="rep in predInt", x="Original SMD", y="Replication SMD")

# d_es_predInt |> ggplot(aes(x=replicated_report_code, y=p_orig))+geom_jitter(height=0, alpha=.5)+
#   #scale_y_log10()+
#   geom_hline(yintercept=.05)
# 
# d_es_predInt |> ggplot(aes(x=replicated_report_code, y=predInt))+geom_jitter(alpha=.5)
```


# Prelim analysis -- Correlation between ES

There's that one ling paper with ES of 10+...

Might want to just hide that point or something instead...

Could weight by precision or something

```{r}
  
d_es |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=as.factor(replicated_report_code)))+
  geom_point()+
  #coord_cartesian(xlim=c(0,5), ylim=c(-1,5))+
  geom_abline(slope=1, intercept=0)+
    geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)

d_es |> ggplot(aes(x=target_d_calc, y=rep_d_calc, color=as.factor(replicated_report_code)))+
  geom_point()+
  coord_cartesian(xlim=c(0,5), ylim=c(-1,4))+
  geom_abline(slope=1, intercept=0)+
  geom_hline(yintercept=0)+
  scale_color_viridis(discrete=T, direction=-1)+
  labs(color="Replicated?", x="Original SMD", y="Replication SMD")
```

# How much missing data?

Note, it may seem weird that we're missing d and SE for many more replications than we are p values. This is because we can't get d_calc if we don't have a filled in value for same direction (but we have p value and unsigned d_calc). 

```{r, message=T}
message("total rows")
d_es_predInt |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |> nrow()

message("number of NAs per column")

d_check_nas <- d_es_predInt |> filter(!status %in% c("missing", "non-experiment", "reproduction")) |> ungroup() |>
    select(target_lastauthor_year, status, academic_year, subfield, target_year,
           stanford_internal,open_data, open_materials, target_on_turk,
           replication_on_turk, within_between, single_vignette, repeated_measure,
           target_N, replication_N,
           target_p_calc, target_d_calc, rep_p_calc, rep_d_calc,
           predInt, p_orig, sub_rep) 

d_check_nas |> summarize(across(everything(),~sum(is.na(.)))) |>
pivot_longer(everything()) |>
  arrange((value)) |>
  filter(value!=0)

message("number of complete rows for full analysis")

d_check_nas |> select(-sub_rep, -subfield) |> filter(across(everything(), ~!is.na(.))) |> nrow()

message("number of rows for subjective w/ demographic/experimental")

d_check_nas |> select(target_lastauthor_year, status, academic_year,  target_year,
           stanford_internal,open_data, open_materials, target_on_turk,
           replication_on_turk, within_between, single_vignette, repeated_measure,
           target_N, replication_N) |> filter(across(everything(), ~!is.na(.))) |> nrow()

message("number of rows for predInt/p_orig w/ demographic/experimental")


d_check_nas |> select(target_lastauthor_year, status, academic_year, target_year,
           stanford_internal,open_data, open_materials, target_on_turk,
           replication_on_turk, within_between, single_vignette, repeated_measure,
           target_N, replication_N, predInt, p_orig) |>  filter(across(everything(), ~!is.na(.))) |> nrow()
```

```{r}
# papers where we don't have everything

d_check_nas |> filter(if_any(everything(), ~is.na(.))) 

d_check_nas |> filter(across(everything(), ~!is.na(.))) 

d_check_nas  |> select(target_lastauthor_year, status, academic_year, target_year,
           stanford_internal,open_data, open_materials, target_on_turk,
           replication_on_turk, within_between, single_vignette, repeated_measure,
           target_N, replication_N, predInt, p_orig) |>  filter(if_any(everything(), ~is.na(.)))
```



# code vars for models


```{r}
d_for_model <- d_es_predInt |> 
  ungroup() |> 
  mutate(pub_year= target_year-mean(target_year),
         log_p =log(target_p_calc),
         log_sample =log(target_N),
         ratio_ss = replication_N/target_N,
         change_platform=ifelse(replication_on_turk==target_on_turk,0,1),
  #this codes 1 if the original was in person, but replication turk/prolific,
  # 0 if they were both on turk/prolific or both in-person (rare, but happens a few times)
        open_data=ifelse(open_data=="yes", 1,0),
         open_mat=ifelse(open_materials=="yes", 1,0),
         stanford=ifelse(stanford_internal=="yes", 1,0),
        is_within=case_when(
            within_between=="within" ~ 1,
            within_between=="mixed" ~ 1,
            within_between=="between" ~ 0),
    log_trials=log(repeated_measure)) |> 
  select(target_lastauthor_year, academic_year, subfield, 
         pub_year, log_p, log_sample, ratio_ss, change_platform, target_d_calc,
           stanford, open_data, open_mat, 
         is_within, single_vignette, log_trials, 
           predInt, p_orig, sub_rep)

summary(d_for_model)

```